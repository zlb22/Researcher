# ============================================
# Researcher - Environment Configuration
# ============================================
# Copy this file to .env and fill in your API keys
# All keys are optional - configure only the providers you plan to use

# ============================================
# LLM Provider Configuration
# ============================================

# --------------------------------------------
# Anthropic Claude (Recommended)
# --------------------------------------------
# Get your API key from: https://console.anthropic.com/
# Supported models: claude-3-5-sonnet-20241022, claude-3-opus-20240229, etc.
ANTHROPIC_API_KEY=sk-ant-xxx

# --------------------------------------------
# OpenAI GPT
# --------------------------------------------
# Get your API key from: https://platform.openai.com/
# Supported models: gpt-4, gpt-4-turbo, gpt-3.5-turbo, etc.
OPENAI_API_KEY=sk-xxx

# Optional: Custom OpenAI-compatible endpoint (for DeepSeek, Ollama, etc.)
# Leave commented if using official OpenAI API
#OPENAI_BASE_URL=https://api.openai.com/v1

# Optional: Override default model
# Default: gpt-4-turbo (if using OpenAI), deepseek-chat (if using DeepSeek)
#OPENAI_MODEL=gpt-4-turbo

# --------------------------------------------
# DeepSeek Configuration (OpenAI-compatible)
# --------------------------------------------
# Get your API key from: https://platform.deepseek.com/
# Uncomment these lines to use DeepSeek instead of OpenAI:
#OPENAI_API_KEY=sk-xxx
#OPENAI_BASE_URL=https://api.deepseek.com/v1
#OPENAI_MODEL=deepseek-chat

# --------------------------------------------
# Ollama Configuration (Local LLM)
# --------------------------------------------
# Install Ollama from: https://ollama.ai/
# Uncomment these lines to use local Ollama models:
#OPENAI_BASE_URL=http://localhost:11434/v1
#OPENAI_MODEL=llama3:latest
# Note: Ollama doesn't require an API key, but set a dummy value:
#OPENAI_API_KEY=ollama

# ============================================
# Search Provider Configuration
# ============================================

# --------------------------------------------
# Tavily Search (Required for Searcher Agent)
# --------------------------------------------
# Get your API key from: https://tavily.com/
# Free tier: 1,000 searches/month
# Used by: Searcher agent for web research
TAVILY_API_KEY=tvly-xxx

# ============================================
# Agent Configuration (Optional)
# ============================================

# Maximum steps per agent execution (prevent infinite loops)
# Default: 50
#MAX_AGENT_STEPS=50

# Default workspace directory
# Default: ./workspace
#WORKSPACE_DIR=./workspace

# Log level: DEBUG, INFO, WARNING, ERROR
# Default: INFO
#LOG_LEVEL=INFO

# ============================================
# Usage Examples
# ============================================

# Example 1: Using Anthropic Claude (Recommended)
# ANTHROPIC_API_KEY=sk-ant-xxx
# TAVILY_API_KEY=tvly-xxx

# Example 2: Using OpenAI GPT-4
# OPENAI_API_KEY=sk-xxx
# TAVILY_API_KEY=tvly-xxx

# Example 3: Using DeepSeek (Cost-effective)
# OPENAI_API_KEY=sk-xxx
# OPENAI_BASE_URL=https://api.deepseek.com/v1
# OPENAI_MODEL=deepseek-chat
# TAVILY_API_KEY=tvly-xxx

# Example 4: Using Local Ollama
# OPENAI_API_KEY=ollama
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_MODEL=llama3:latest
# TAVILY_API_KEY=tvly-xxx

# ============================================
# Notes
# ============================================
# 1. At least one LLM provider (Anthropic or OpenAI) is required
# 2. Tavily API key is required for web search functionality
# 3. Environment variables can also be set directly in your shell
# 4. Priority: .env file > shell environment variables
# 5. Never commit .env file to version control (already in .gitignore)
